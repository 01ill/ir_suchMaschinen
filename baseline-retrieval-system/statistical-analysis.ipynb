{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab Tutorial: Statistical Analysis\n",
    "\n",
    "This tutorial shows how to conduct a hypothesis test to compare two retrieval approaches.\n",
    "The two runs compared in this example are loaded from the TIRA cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Ensure that libraries are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n",
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.7 (build: craigm 2022-11-10 18:30), helper_version=0.0.7]\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ir/lib/python3.10/site-packages/tira/third_party_integrations.py:39: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "The following code will have the same effect:\n",
      "pt.java.add_package('com.github.terrierteam', 'terrier-prf', '-SNAPSHOT')\n",
      "pt.terrier.set_version('5.7')\n",
      "pt.terrier.set_helper_version('0.0.7')\n",
      "pt.java.mavenresolver.offline()\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init(\n"
     ]
    }
   ],
   "source": [
    "# This command loads and starts PyTerrier so that it also works in TIRA.\n",
    "\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "\n",
    "ensure_pyterrier_is_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_66697/811612812.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not started():\n"
     ]
    }
   ],
   "source": [
    "# PyTerrier must be imported after `ensure_pyterrier_is_loaded` is called.\n",
    "\n",
    "from pyterrier import started, init\n",
    "\n",
    "if not started():\n",
    "    init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRDSDataset('ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier import get_dataset\n",
    "\n",
    "dataset_train = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training')\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRDSDataset('ir-lab-wise-2024/subsampled-ms-marco-rag-20250105-training')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_validation = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-rag-20250105-training')\n",
    "dataset_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRDSDataset('ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test')\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For development, let's use the training set for the experiments.\n",
    "dataset = dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the retrieval pipeline with TIRA\n",
    "\n",
    "In this example, we will use two existing submitted runs and load the approaches via the TIRA API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.rest_api_client import Client\n",
    "\n",
    "tira_client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach IDs below follow the structure: `<task>/<team>/<submission>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tira.pyterrier_util.TiraSourceTransformer at 0x12326b160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approach_baseline = tira_client.pt.from_retriever_submission(\n",
    "    approach='ir-lab-wise-2024/ir-wise-24-suchmaschinen/BM25 + ReRanking (monoT5 BL)',\n",
    "    dataset='subsampled-ms-marco-deep-learning-20241201-training',\n",
    ")\n",
    "approach_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 1.11MiB [00:00, 20.3MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /Users/till/.tira/extracted_runs/ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training/ir-wise-24-tutors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tira.pyterrier_util.TiraSourceTransformer at 0x105a0c9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach_baseline = tira_client.pt.from_retriever_submission(\n",
    "#     approach='ir-lab-wise-2024/ir-wise-24-tutors/Retrieval Baseline',\n",
    "#     dataset='subsampled-ms-marco-deep-learning-20241201-training',\n",
    "# )\n",
    "# approach_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 18.2kiB [00:00, 3.28MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /Users/till/.tira/extracted_runs/ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training/ir-wise-24-suchmaschinen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tira.pyterrier_util.TiraSourceTransformer at 0x123a29120>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approach_new = tira_client.pt.from_retriever_submission(\n",
    "    approach='ir-lab-wise-2024/ir-wise-24-suchmaschinen/BM25 + ReRanking (mono+duoT5)',\n",
    "    dataset='subsampled-ms-marco-deep-learning-20241201-training',\n",
    ")\n",
    "approach_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 1.37MiB [00:00, 15.4MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /Users/till/.tira/extracted_runs/ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training/ir-wise-24-th25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tira.pyterrier_util.TiraSourceTransformer at 0x1231b7b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach_new = tira_client.pt.from_retriever_submission(\n",
    "#     approach='ir-lab-wise-2024/ir-wise-24-th25/BM25 + MonoT5 Rerank',\n",
    "#     dataset='subsampled-ms-marco-deep-learning-20241201-training',\n",
    "# )\n",
    "# approach_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Measure effectiveness\n",
    "\n",
    "Now let us measure the nDCG@10 effectiveness of both systems on the Touch√© 2020 task 1 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>qid</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>monoT5</td>\n",
       "      <td>405717</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.595927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>monoT5+duoT5</td>\n",
       "      <td>640502</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>monoT5+duoT5</td>\n",
       "      <td>1114819</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.877514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>monoT5</td>\n",
       "      <td>168216</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.812071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>monoT5+duoT5</td>\n",
       "      <td>405717</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.634123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>monoT5+duoT5</td>\n",
       "      <td>121171</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.548893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>monoT5</td>\n",
       "      <td>1114646</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.885673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>monoT5</td>\n",
       "      <td>174463</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.711944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>monoT5</td>\n",
       "      <td>489204</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.224446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monoT5</td>\n",
       "      <td>1064670</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.801862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name      qid      measure     value\n",
       "92         monoT5   405717  ndcg_cut_10  0.595927\n",
       "139  monoT5+duoT5   640502  ndcg_cut_10  1.000000\n",
       "175  monoT5+duoT5  1114819  ndcg_cut_10  0.877514\n",
       "60         monoT5   168216  ndcg_cut_10  0.812071\n",
       "189  monoT5+duoT5   405717  ndcg_cut_10  0.634123\n",
       "121  monoT5+duoT5   121171  ndcg_cut_10  0.548893\n",
       "89         monoT5  1114646  ndcg_cut_10  0.885673\n",
       "29         monoT5   174463  ndcg_cut_10  0.711944\n",
       "58         monoT5   489204  ndcg_cut_10  0.224446\n",
       "4          monoT5  1064670  ndcg_cut_10  0.801862"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.pipelines import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    retr_systems=[\n",
    "        approach_baseline,\n",
    "        approach_new,\n",
    "    ],\n",
    "    topics=dataset_train.get_topics(\"query\"),\n",
    "    qrels=dataset_train.get_qrels(),\n",
    "    eval_metrics=[\"ndcg_cut_10\"],\n",
    "    names=[\n",
    "        \"monoT5\",\n",
    "        \"monoT5+duoT5\",\n",
    "    ],\n",
    "    perquery=True,\n",
    ")\n",
    "experiment.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame shows the nDCG@10 values measured for each query and both systems. \\\n",
    "So we have pairs of measurements where the same metric (i.e., nDCG@10) is measured using the same input (e.g., query #1) but for two different systems.\n",
    "Let's re-arrange the data frame so that the effectiveness values are in separate columns, not rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>measure</th>\n",
       "      <th>value_baseline</th>\n",
       "      <th>value_approach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030303</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.627356</td>\n",
       "      <td>0.733750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037496</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.912539</td>\n",
       "      <td>0.902150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037798</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.199613</td>\n",
       "      <td>0.220807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043135</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.845994</td>\n",
       "      <td>0.730450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104861</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1051399</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.821843</td>\n",
       "      <td>0.817671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1063750</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.871021</td>\n",
       "      <td>0.841178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1064670</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.801862</td>\n",
       "      <td>0.752252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1071750</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.726809</td>\n",
       "      <td>0.688409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1103812</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.744751</td>\n",
       "      <td>0.659619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid      measure  value_baseline  value_approach\n",
       "0  1030303  ndcg_cut_10        0.627356        0.733750\n",
       "1  1037496  ndcg_cut_10        0.912539        0.902150\n",
       "2  1037798  ndcg_cut_10        0.199613        0.220807\n",
       "3  1043135  ndcg_cut_10        0.845994        0.730450\n",
       "4   104861  ndcg_cut_10        1.000000        1.000000\n",
       "5  1051399  ndcg_cut_10        0.821843        0.817671\n",
       "6  1063750  ndcg_cut_10        0.871021        0.841178\n",
       "7  1064670  ndcg_cut_10        0.801862        0.752252\n",
       "8  1071750  ndcg_cut_10        0.726809        0.688409\n",
       "9  1103812  ndcg_cut_10        0.744751        0.659619"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_baseline = experiment[experiment[\"name\"] == \"monoT5\"]\\\n",
    "    .drop(columns=[\"name\"])\n",
    "experiment_approach = experiment[experiment[\"name\"] == \"monoT5+duoT5\"]\\\n",
    "    .drop(columns=[\"name\"])\n",
    "\n",
    "experiment_paired = experiment_baseline.merge(\n",
    "    experiment_approach,\n",
    "    on=[\"qid\", \"measure\"],\n",
    "    suffixes=(\"_baseline\", \"_approach\"),\n",
    ")\n",
    "experiment_paired.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Conduct hypothesis tests\n",
    "\n",
    "On this _paired_ measurement data, we can now conduct _paired_ t-tests to test for statistical significance of given hypotheses.\n",
    "Remember that the choice of your test depends (amongst other factors) on how the hypothesis is formulated.\n",
    "\n",
    "Let us test some hypotheses to get a feeling of what this means:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis 1: The new approach has a significantly different nDCG@10 on the chosen dataset than the baseline.\n",
    "(Hint: For your own tests, you'd want to replace the approach and dataset names with the actual names above.)\n",
    "\n",
    "Significance test: two-sided paired t-test \\\n",
    "Significance level: $\\alpha = 0.05$ (i.e., the effect is only considered significant if $p < 0.05$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316784914254621"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "ttest_rel(\n",
    "    experiment_paired[\"value_approach\"],\n",
    "    experiment_paired[\"value_baseline\"],\n",
    "    alternative='two-sided',\n",
    ").pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above value is called $p$, the probability of the corresponding null hypothesis (the probability that the effect would be observed by chance). \\\n",
    "If this is lower than our significance level $\\alpha$, we can reject the null hypothesis and confirm the hypothesis 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it would be great to find out which is better. \\\n",
    "One way could be to formulate a hypothesis with a predefined \"direction\". In this example we assume our new approach to be better.\n",
    "\n",
    "#### Hypothesis 2: The new approach has a significantly higher nDCG@10 on the chosen dataset than the baseline.\n",
    "\n",
    "Significance test: one-sided paired t-test \\\n",
    "Significance level: $\\alpha = 0.05$ (or $p < 0.05$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6693111780797145e-35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "ttest_rel(\n",
    "    experiment_paired[\"value_approach\"],\n",
    "    experiment_paired[\"value_baseline\"],\n",
    "    alternative='greater',\n",
    ").pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if the probability $p$ of the null hypothesis is lower than our significance level $\\alpha$, then we can reject the null hypothesis and confirm hypothesis 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the opposite direction: the new approach could be worse w.r.t. nDCG@10 than the baseline.\n",
    "\n",
    "#### Hypothesis 2: The new approach has a significantly lower nDCG@10 on the chosen dataset than the baseline.\n",
    "\n",
    "Significance test: one-sided paired t-test \\\n",
    "Significance level: $\\alpha = 0.05$ (or $p < 0.05$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5841607542872689"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "ttest_rel(\n",
    "    experiment_paired[\"value_approach\"],\n",
    "    experiment_paired[\"value_baseline\"],\n",
    "    alternative='less',\n",
    ").pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if the probability $p$ of the null hypothesis is lower than our significance level $\\alpha$, then we can reject the null hypothesis and confirm hypothesis 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
