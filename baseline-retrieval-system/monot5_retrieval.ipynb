{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einrichtung\n",
    "- Installieren der Packages\n",
    "- Initialisieren von Pyterrier\n",
    "- Laden der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade tira ir-datasets python-terrier \n",
    "!pip3 install --upgrade pyterrier-caching pyterrier_t5\n",
    "# !pip3 install --upgrade git+https://github.com/terrierteam/pyterrier_t5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.java.started():\n",
    "    pt.java.init()\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import get_dataset\n",
    "\n",
    "pt_dataset = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training')\n",
    "pt_dataset_new = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-rag-20250105-training')\n",
    "pt_dataset_test = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indizes erstellen\n",
    "- für alle drei Datensätze wird ein Index erstellt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 25752/68261 [00:04<00:06, 6770.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:18:51.899 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [00:08<00:00, 7873.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:18:57.029 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "from pyterrier import IterDictIndexer\n",
    "\n",
    "indexer = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    ")\n",
    "index = indexer.index(pt_dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-rag-20250105-training documents: 100%|██████████| 113227/113227 [00:31<00:00, 3557.55it/s]\n"
     ]
    }
   ],
   "source": [
    "indexer_new = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index_new\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    ")\n",
    "index_new = indexer_new.index(pt_dataset_new.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test documents: 100%|██████████| 125112/125112 [00:43<00:00, 2903.12it/s]\n"
     ]
    }
   ],
   "source": [
    "indexer_test = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index_test\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    ")\n",
    "index_test = indexer_test.index(pt_dataset_test.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines definieren\n",
    "- BM25 mit den jeweiligen Indizies\n",
    "- MonoT5 in gecachter Variante\n",
    "- DuoT5 in Kombination mit MonoT5 (gecacht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_96155/3998526657.py:3: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25 = BatchRetrieve(index, wmodel=\"BM25\")\n",
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_96155/3998526657.py:4: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25_new = BatchRetrieve(index_new, wmodel=\"BM25\")\n",
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_96155/3998526657.py:5: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25_test = BatchRetrieve(index_test, wmodel=\"BM25\")\n"
     ]
    }
   ],
   "source": [
    "from pyterrier import BatchRetrieve\n",
    "\n",
    "bm25 = BatchRetrieve(index, wmodel=\"BM25\")\n",
    "bm25_new = BatchRetrieve(index_new, wmodel=\"BM25\")\n",
    "bm25_test = BatchRetrieve(index_test, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_t5 import MonoT5ReRanker, DuoT5ReRanker\n",
    "from pyterrier_caching import SparseScorerCache\n",
    "monoT5 = MonoT5ReRanker()\n",
    "duoT5 = DuoT5ReRanker()\n",
    "\n",
    "monoT5 = SparseScorerCache('monoT5_fix.cache', monoT5, verbose=True) # Caching für MonoT5\n",
    "\n",
    "pipeline_mono_t5 = (bm25 % 100 >> pt.text.get_text(pt_dataset, \"text\") >> monoT5) ^ (bm25)\n",
    "pipeline_duo_t5 = (pipeline_mono_t5 % 5 >> duoT5) ^ pipeline_mono_t5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testen auf dem Standard-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:   0%|          | 0/2 [00:00<?, ?system/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x150498d90>, group='query', key='docno'): 100 hit(s), 0 miss(es)\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x150498d90>, group='query', key='docno'): 100 hit(s), 0 miss(es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "duoT5: 100%|██████████| 1/1 [00:04<00:00,  4.48s/queries]\n",
      "pt.Experiment: 100%|██████████| 2/2 [00:04<00:00,  2.39s/system]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x150498d90>, group='query', key='docno'): 100 hit(s), 0 miss(es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25+monoT5</td>\n",
       "      <td>0.627356</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25+monoT5+duoT5</td>\n",
       "      <td>0.748086</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  ndcg_cut_10  P_10\n",
       "0        BM25+monoT5     0.627356   0.4\n",
       "1  BM25+monoT5+duoT5     0.748086   0.4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier import Experiment\n",
    "# Run experiment\n",
    "Experiment(\n",
    "    retr_systems=[\n",
    "        pipeline_mono_t5,\n",
    "        pipeline_duo_t5,\n",
    "    ],\n",
    "    names=[\n",
    "        \"BM25+monoT5\",\n",
    "        \"BM25+monoT5+duoT5\",\n",
    "    ],\n",
    "    topics=pt_dataset.get_topics('text').head(1),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    eval_metrics=[\"ndcg_cut_10\", \"P_10\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimieren von MonoT5 auf dem Standard-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_monot5():\n",
    "    mono2 = pt.text.get_text(pt_dataset, \"text\") >> monoT5 # Pipeline für MonoT5\n",
    "    mono_cached = SparseScorerCache('monoT5.cache', mono2, verbose=True) # Caching für MonoT5\n",
    "    duo2 = pt.text.get_text(pt_dataset, \"text\") >> duoT5 # Pipeline für DuoT5\n",
    "    duo_cached = SparseScorerCache('duoT5.cache', duo2, verbose=True) # Caching für DuoT5\n",
    "    experiment = []\n",
    "    for mono_cutoff in range(25, 5000, 25):\n",
    "        inp = (bm25 % mono_cutoff).transform(pt_dataset.get_topics('text').head(first_x_topics)) # BM25 auf den ersten x Topics anwenden. Dabei cutoff von 100 Dokumenten\n",
    "        mono_results = mono_cached.transform(inp) # MonoT5 wird auf die Ergebnisse von BM25 angewendet\n",
    "\n",
    "        for duo_cutoff in range(5, 6):\n",
    "            mono_results_cutoff = (mono_cached % duo_cutoff).transform(inp)\n",
    "            duo_results = duo_cached.transform(mono_results_cutoff)\n",
    "            exp = Experiment(\n",
    "                [mono_results, duo_results],\n",
    "                topics = pt_dataset.get_topics('text'),\n",
    "                qrels = pt_dataset.get_qrels(),\n",
    "                eval_metrics =['ndcg_cut_5', 'ndcg_cut_10', \"mrt\"],\n",
    "                names=[\"monoT5\", \"monoT5+duoT5\"],\n",
    "                round = 3,\n",
    "                baseline=0\n",
    "            )\n",
    "            experiment.append({'mono_cutoff': mono_cutoff, 'duo_cutoff': duo_cutoff, 'mono_ndcg_5': exp['ndcg_cut_5'][0], 'duo_ndcg_5': exp['ndcg_cut_5'][1], 'mono_ndcg': exp['ndcg_cut_10'][0], 'duo_ndcg': exp['ndcg_cut_10'][1], 'p_value': exp['ndcg_cut_10 p-value'][1]})\n",
    "            print('Mono Cutoff:', mono_cutoff, ', Duo Cutoff:', duo_cutoff, ', NDCG@10 MonoT5:', exp['ndcg_cut_10'][0], ', NDCG@10 DuoT5:', exp['ndcg_cut_10'][1], ', p-value:', exp['ndcg_cut_10 p-value'][1])\n",
    "    return experiment\n",
    "\n",
    "experiment = run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abgabe der Runs\n",
    "- je Datensatz zwei Runs (MonoT5 und MonoT5+DuoT5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline = bm25(pt_dataset.get_topics('text'))\n",
    "run_baseline_new = bm25_new(pt_dataset_new.get_topics('text'))\n",
    "run_baseline_test = bm25_test(pt_dataset_test.get_topics('text'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
