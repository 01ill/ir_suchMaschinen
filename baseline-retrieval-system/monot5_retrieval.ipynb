{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einrichtung\n",
    "- Installieren der Packages\n",
    "- Initialisieren von Pyterrier\n",
    "- Laden der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade tira ir-datasets python-terrier \n",
    "!pip3 install --upgrade pyterrier-caching pyterrier_t5\n",
    "# !pip3 install --upgrade git+https://github.com/terrierteam/pyterrier_t5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.java.started():\n",
    "    pt.java.init()\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import get_dataset\n",
    "\n",
    "pt_dataset = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training')\n",
    "pt_dataset_new = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-rag-20250105-training')\n",
    "pt_dataset_test = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indizes erstellen\n",
    "- für alle drei Datensätze wird ein Index erstellt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 25752/68261 [00:04<00:06, 6770.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:18:51.899 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [00:08<00:00, 7873.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:18:57.029 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "from pyterrier import IterDictIndexer\n",
    "\n",
    "indexer = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    ")\n",
    "index = indexer.index(pt_dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-rag-20250105-training documents: 100%|██████████| 113227/113227 [00:31<00:00, 3557.55it/s]\n"
     ]
    }
   ],
   "source": [
    "indexer_new = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index_new\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    ")\n",
    "index_new = indexer_new.index(pt_dataset_new.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test documents: 100%|██████████| 125112/125112 [00:43<00:00, 2903.12it/s]\n"
     ]
    }
   ],
   "source": [
    "indexer_test = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index_test\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    ")\n",
    "index_test = indexer_test.index(pt_dataset_test.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines definieren\n",
    "- BM25 mit den jeweiligen Indizies\n",
    "- MonoT5 in gecachter Variante\n",
    "- DuoT5 in Kombination mit MonoT5 (gecacht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_96155/3998526657.py:3: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25 = BatchRetrieve(index, wmodel=\"BM25\")\n",
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_96155/3998526657.py:4: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25_new = BatchRetrieve(index_new, wmodel=\"BM25\")\n",
      "/var/folders/2z/hftmcxnx6857z5y2jcyv934h0000gn/T/ipykernel_96155/3998526657.py:5: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25_test = BatchRetrieve(index_test, wmodel=\"BM25\")\n"
     ]
    }
   ],
   "source": [
    "from pyterrier import BatchRetrieve\n",
    "\n",
    "bm25 = BatchRetrieve(index, wmodel=\"BM25\")\n",
    "bm25_new = BatchRetrieve(index_new, wmodel=\"BM25\")\n",
    "bm25_test = BatchRetrieve(index_test, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_t5 import MonoT5ReRanker, DuoT5ReRanker\n",
    "from pyterrier_caching import SparseScorerCache\n",
    "_monoT5 = MonoT5ReRanker()\n",
    "duoT5 = DuoT5ReRanker()\n",
    "\n",
    "def mono_factory(cutoff, bm25, monoT5):\n",
    "    return (bm25 % cutoff >> pt.text.get_text(pt_dataset, \"text\") >> monoT5) ^ (bm25)\n",
    "\n",
    "def duo_pipeline(cutoff, mono_pipeline):\n",
    "    return (mono_pipeline % cutoff >> duoT5) ^ mono_pipeline\n",
    "\n",
    "monoT5 = SparseScorerCache('monoT5_fix.cache', _monoT5, verbose=True)\n",
    "monoT5_new = SparseScorerCache('monoT5_new_fix.cache', _monoT5, verbose=True)\n",
    "monoT5_test = SparseScorerCache('monoT5_test_fix.cache', _monoT5, verbose=True)\n",
    "\n",
    "pipeline_mono_t5 = (bm25 >> pt.text.get_text(pt_dataset, \"text\") >> monoT5) ^ (bm25)\n",
    "pipeline_duo_t5 = (pipeline_mono_t5 % 5 >> duoT5) ^ pipeline_mono_t5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testen auf dem Standard-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monoT5: 100%|██████████| 22380/22380 [2:26:28<00:00,  2.55batches/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 1550 hit(s), 89517 miss(es)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25+monoT5</td>\n",
       "      <td>0.727375</td>\n",
       "      <td>0.787629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  ndcg_cut_10      P_10\n",
       "0  BM25+monoT5     0.727375  0.787629"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier import Experiment\n",
    "# Run experiment\n",
    "Experiment(\n",
    "    retr_systems=[\n",
    "        pipeline_mono_t5,\n",
    "#        pipeline_duo_t5,\n",
    "    ],\n",
    "    names=[\n",
    "        \"BM25+monoT5\",\n",
    "#        \"BM25+monoT5+duoT5\",\n",
    "    ],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    eval_metrics=[\"ndcg_cut_10\", \"P_10\"],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimieren von MonoT5 auf dem Standard-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 2405 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 25 , NDCG@10: 0.622\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 4783 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 50 , NDCG@10: 0.662\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 7158 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 75 , NDCG@10: 0.68\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 9533 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 100 , NDCG@10: 0.684\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 11908 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 125 , NDCG@10: 0.684\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 14283 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 150 , NDCG@10: 0.695\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 16658 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 175 , NDCG@10: 0.704\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 19017 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 200 , NDCG@10: 0.704\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 21367 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 225 , NDCG@10: 0.707\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 23717 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 250 , NDCG@10: 0.706\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 26057 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 275 , NDCG@10: 0.709\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 28382 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 300 , NDCG@10: 0.711\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 30707 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 325 , NDCG@10: 0.719\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 33027 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 350 , NDCG@10: 0.722\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 35327 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 375 , NDCG@10: 0.723\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 37627 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 400 , NDCG@10: 0.726\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 39927 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 425 , NDCG@10: 0.727\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 42227 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 450 , NDCG@10: 0.727\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 44527 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 475 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 46827 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 500 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 49127 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 525 , NDCG@10: 0.729\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 51410 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 550 , NDCG@10: 0.727\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 53685 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 575 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 55960 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 600 , NDCG@10: 0.727\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 58225 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 625 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 60475 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 650 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 62712 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 675 , NDCG@10: 0.729\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 64937 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 700 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 67162 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 725 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 69387 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 750 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 71601 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 775 , NDCG@10: 0.729\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 73799 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 800 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 75974 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 825 , NDCG@10: 0.729\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 78149 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 850 , NDCG@10: 0.727\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 80324 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 875 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 82499 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 900 , NDCG@10: 0.729\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 84654 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 925 , NDCG@10: 0.729\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 86804 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 950 , NDCG@10: 0.728\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 88942 hit(s), 0 miss(es)\n",
      "Mono Cutoff: 975 , NDCG@10: 0.727\n",
      "525\n"
     ]
    }
   ],
   "source": [
    "def optimize_monot5():\n",
    "    max_ndcg = 0\n",
    "    best_cutoff = 0\n",
    "    for mono_cutoff in range(25, 1000, 25):\n",
    "        pipeline_mono_t5 = (bm25 % mono_cutoff >> pt.text.get_text(pt_dataset, \"text\") >> monoT5) ^ (bm25)\n",
    "        exp = Experiment(\n",
    "            [pipeline_mono_t5],\n",
    "            topics = pt_dataset.get_topics('text'),\n",
    "            qrels = pt_dataset.get_qrels(),\n",
    "            eval_metrics =['ndcg_cut_10'],\n",
    "            names=[\"monoT5\"],\n",
    "            round = 3,\n",
    "            baseline=0\n",
    "        )\n",
    "        new_ndcg = exp['ndcg_cut_10'][0]\n",
    "        if exp['ndcg_cut_10'][0] > max_ndcg:\n",
    "            max_ndcg = new_ndcg\n",
    "            best_cutoff = mono_cutoff\n",
    "        print('Mono Cutoff:', mono_cutoff, ', NDCG@10:', exp['ndcg_cut_10'][0])\n",
    "    return best_cutoff\n",
    "\n",
    "mono_cutoff = optimize_monot5()\n",
    "print(\"Der optimale Mono-Cutoff ist:\", mono_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierung von DuoT5\n",
    "- es wird der beste ermittelte MonoT5-Cutoff (525) genutzt und damit verschiedene DuoT5-Cutoffs (3,5,10,15) getestet\n",
    "- der beste duoT5-Cutoff wird gewählt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 49127 hit(s), 0 miss(es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "duoT5: 100%|██████████| 97/97 [01:12<00:00,  1.34queries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 49127 hit(s), 0 miss(es)\n",
      "Duo Cutoff: 3 , NDCG@10: 0.73\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 49127 hit(s), 0 miss(es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "duoT5: 100%|██████████| 97/97 [04:23<00:00,  2.72s/queries]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 49127 hit(s), 0 miss(es)\n",
      "Duo Cutoff: 5 , NDCG@10: 0.733\n",
      "Sqlite3ScorerCache('monoT5_fix.cache', <pyterrier_t5.MonoT5ReRanker object at 0x15047e7d0>, group='query', key='docno'): 49127 hit(s), 0 miss(es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "duoT5:  31%|███       | 30/97 [08:35<17:23, 15.58s/queries]"
     ]
    }
   ],
   "source": [
    "def optimize_duot5(mono_cutoff = 525):\n",
    "    max_ndcg = 0\n",
    "    best_cutoff = 0\n",
    "    for duo_cutoff in [3,5,10,15]:\n",
    "        pipeline_mono_t5 = (bm25 % mono_cutoff >> pt.text.get_text(pt_dataset, \"text\") >> monoT5) ^ (bm25)\n",
    "        pipeline_duo_t5 = (pipeline_mono_t5 % duo_cutoff >> duoT5) ^ pipeline_mono_t5\n",
    "        exp = Experiment(\n",
    "            [pipeline_duo_t5],\n",
    "            topics = pt_dataset.get_topics('text'),\n",
    "            qrels = pt_dataset.get_qrels(),\n",
    "            eval_metrics =['ndcg_cut_10'],\n",
    "            names=[\"duoT5\"],\n",
    "            round = 3,\n",
    "            baseline=0\n",
    "        )\n",
    "        new_ndcg = exp['ndcg_cut_10'][0]\n",
    "        if exp['ndcg_cut_10'][0] > max_ndcg:\n",
    "            max_ndcg = new_ndcg\n",
    "            best_cutoff = duo_cutoff\n",
    "        print('Duo Cutoff:', duo_cutoff, ', NDCG@10:', exp['ndcg_cut_10'][0])\n",
    "    return best_cutoff\n",
    "\n",
    "duo_cutoff = optimize_duot5(mono_cutoff)\n",
    "print(\"Der optimale Duo-Cutoff ist:\", duo_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_cutoff = 525\n",
    "duo_cutoff = 15\n",
    "\n",
    "pipeline_mono_optimized = (bm25 % mono_cutoff >> pt.text.get_text(pt_dataset, \"text\") >> monoT5) ^ (bm25)\n",
    "pipeline_duo_optimized = (pipeline_mono_t5 % duo_cutoff >> duoT5) ^ pipeline_mono_t5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abgabe der Runs\n",
    "- je Datensatz zwei Runs (MonoT5 und MonoT5+DuoT5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline = pipeline_mono_optimized(pt_dataset.get_topics('text'))\n",
    "run_baseline_new = pipeline_mono_optimized(pt_dataset_new.get_topics('text'))\n",
    "run_baseline_test = pipeline_mono_optimized(pt_dataset_test.get_topics('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_duo = pipeline_duo_optimized(pt_dataset.get_topics('text'))\n",
    "run_duo_new = pipeline_duo_optimized(pt_dataset_new.get_topics('text'))\n",
    "run_duo_test = pipeline_duo_optimized(pt_dataset_test.get_topics('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import persist_and_normalize_run\n",
    "persist_and_normalize_run(\n",
    "    run_baseline,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='monoT5-BL-suchMaschinen', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset,\n",
    ")\n",
    "persist_and_normalize_run(\n",
    "    run_baseline_new,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='monoT5-BL-suchMaschinen', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset_new,\n",
    ")\n",
    "persist_and_normalize_run(\n",
    "    run_baseline_test,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='monoT5-BL-suchMaschinen', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_and_normalize_run(\n",
    "    run_duo,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='duoT5-suchMaschinen', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset,\n",
    ")\n",
    "persist_and_normalize_run(\n",
    "    run_duo_new,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='duoT5-suchMaschinen', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset_new,\n",
    ")\n",
    "persist_and_normalize_run(\n",
    "    run_duo_test,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='duoT5-suchMaschinen', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
